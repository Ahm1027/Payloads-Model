{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Payload_Model_Ngrams.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODgeVoAG0H4fWVW+AXE4uQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahm1027/Payloads-Model/blob/master/Payload_Model_Ngrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPnUtvD1hqtl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from nltk import ngrams\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import binascii"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFlRLYKeh3L-",
        "outputId": "b7dae5eb-4ed5-42cc-8895-62604d71acab"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydpQin-pHgUS"
      },
      "source": [
        "def get_hexdump(executable, num_of_ngrams=4):\n",
        "  executable = open(executable, 'rb')\n",
        "  data = executable.read()\n",
        "  executable.close()\n",
        "  data2hex = bin2hex(data)\n",
        "  output = ngrams(data2hex.split(\" \"), num_of_ngrams)\n",
        "  return [ ''.join(grams) for grams in output]\n",
        "\n",
        "def bin2hex(data):\n",
        "  data2hex = \"\"\n",
        "  for byte in data:\n",
        "    hex = str(binascii.hexlify(bytes([byte]))).split(\"'\")\n",
        "    if (len(hex) >= 2):\n",
        "      data2hex += hex[1]+\" \"\n",
        "    else:\n",
        "      data2hex += hex[0]+\" \"\n",
        "  return data2hex\n",
        "\n",
        "# def generate_ngrams(text, WordsToCombine):\n",
        "#     words = text.split()\n",
        "#     output = []  \n",
        "#     for i in range(len(words)- WordsToCombine+1):\n",
        "#       word = ''\n",
        "#       for i in range (i, i+WordsToCombine):\n",
        "#         word = word + words[i]\n",
        "#       output.append(word)\n",
        "#     return output\n",
        "\n",
        "# def calculateTotalCounts(uniqueOutput, output):\n",
        "#   Uniquecounts = []\n",
        "#   for i in range(len(uniqueOutput)):\n",
        "#     count = 0\n",
        "#     for j in range(len(output)):\n",
        "#       if output[j] == uniqueOutput[i]:\n",
        "#         count = count+1\n",
        "#     Uniquecounts.append(count)\n",
        "#   return Uniquecounts"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R30u9CEZHjwk"
      },
      "source": [
        "def vectorize(data):\n",
        "  vectorizer = CountVectorizer()\n",
        "  vectorizer.fit(data)\n",
        "  vectorized = vectorizer.transform(data)\n",
        "  return vectorizer, vectorized"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3berQxFHmhS"
      },
      "source": [
        "def arrangeAndSort(data_vectorizer, data_vectorized):\n",
        "  data_arranged = list(zip(data_vectorizer.get_feature_names(), data_vectorized.sum(0).getA1()))\n",
        "  data_sorted = sorted(data_arranged, key=lambda item: item[1], reverse=True)\n",
        "  return data_sorted"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgPCOVs8zNzT",
        "outputId": "5036b262-71c5-40e7-e1fb-e3befd1010ab"
      },
      "source": [
        "def resolveMalwareFiles(FOLDER_PATHS, num_of_features=2000):\n",
        "  stopCheck, prev=0, 0\n",
        "  globalFeatures = np.array([])\n",
        "  for files in os.listdir(FOLDER_PATHS):\n",
        "    filepath = r\"/content/drive/MyDrive/Payloads/\"+files\n",
        "    data = get_hexdump(filepath)\n",
        "    return data\n",
        "    data_vectorizer, data_vectorized = vectorize(data)\n",
        "    data_sorted = arrangeAndSort(data_vectorizer, data_vectorized)[:num_of_features]\n",
        "    if (len(globalFeatures) == 0):\n",
        "      globalFeatures = np.array(data_sorted)[:, 0].astype(str).tolist()\n",
        "    else:\n",
        "      globalFeatures = np.append(globalFeatures, np.array(data_sorted)[:, 0].astype(str).tolist())\n",
        "      indexes = np.unique(globalFeatures, return_index=True)[1]\n",
        "      globalFeatures = [globalFeatures[index] for index in sorted(indexes)]\n",
        "    if (stopCheck == prev+10):\n",
        "      prev = stopCheck\n",
        "      print(\"%f percent completed\"%((stopCheck/1000)*100), end=\", \")\n",
        "      print(\"Number of Features: %d\"%(len(globalFeatures)))\n",
        "    stopCheck += 1\n",
        "  return globalFeatures\n",
        "\n",
        "globalFeatures = resolveMalwareFiles(r\"/content/drive/MyDrive/Payloads\")\n",
        "print(len(globalFeatures))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "688721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lARiqCPjqXf"
      },
      "source": [
        "x = pd.HDFStore(\"some_file.hdf\")\n",
        "\n",
        "x.append(\"a\", pd.DataFrame(globalFeatures))\n",
        "x.close()\n",
        "\n",
        "my_data = pandas.HDFStore(\"some_file.hdf\")\n",
        "usable_a_copy = my_data[\"a\"]\n",
        "\n",
        "copy_as_nparray = usable_a_copy.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VjPWUF-lK6x"
      },
      "source": [
        "globalFeatures.tofile('features.dat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UXHtpbYl9Cn"
      },
      "source": [
        "np.save('features_np.npy', globalFeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ6tPr0xBB66"
      },
      "source": [
        "def normalizeFeatures(data):\n",
        "  data_scaled = (data - data.min()) / (data.max() - data.min())   #MinMax Normalization\n",
        "  return data_scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgDy9sURJLKP",
        "outputId": "46d15747-a198-4aec-e4e7-60dd4b7bca7e"
      },
      "source": [
        "def generateGlobalVocab(data):\n",
        "  globalFeatures = np.array([])\n",
        "  for key, value in data:\n",
        "    l = np.array(value)[:,0]\n",
        "    globalFeatures = np.concatenate([globalFeatures, l], axis=0)\n",
        "\n",
        "  globalFeatures\n",
        "\n",
        "def find_first_no_jit(item, vec):\n",
        "  for i in range(vec.size):\n",
        "    if item == vec[i]:\n",
        "      return i\n",
        "  return -1\n",
        "\n",
        "def mergeWithGlobalVocab(data, globalFeatures):\n",
        "  if globalFeatures.size == 0:\n",
        "    globalFeatures = np.concatenate([globalFeatures, np.array(data)[:, 0].astype(str).tolist()])\n",
        "    print(globalFeatures.shape)\n",
        "  else:\n",
        "    #globalFeatures[0] = np.concatenate([globalFeatures, np.array(data)[:, 0].astype(str).tolist()])\n",
        "    print(globalFeatures.shape)\n",
        "    globalFeatures[0] = np.append(globalFeatures[0], [globalFeatures, np.array(data)[:, 0].astype(str).tolist()])\n",
        "    print(len(globalFeatures[0]))\n",
        "    globalFeatures[0], indexes = np.unique(globalFeatures, return_index=True)\n",
        "    globalFeatures[0] = globalFeatures[np.sort(indexes)]\n",
        "  print(globalFeatures)\n",
        "  features = [0]*globalFeatures.size\n",
        "  for x in data:\n",
        "    id = find_first_no_jit(x[0], globalFeatures)\n",
        "    if (id != -1):\n",
        "      features[id] = x[1]\n",
        "  globalFeatures = np.vstack((globalFeatures, features))\n",
        "  return globalFeatures"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 2000)"
            ]
          },
          "execution_count": 233,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGpgwxgnBFB3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZGvdVtcqUUK"
      },
      "source": [
        "# compressed_SVD = TruncatedSVD(30)\n",
        "# compressed_data = compressed_SVD.fit_transform(features_frequency)\n",
        "# pd.DataFrame(compressed_SVD.components_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPGNSrMvVf-j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}